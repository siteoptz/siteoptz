#!/usr/bin/env node

const fs = require('fs').promises;
const path = require('path');

console.log('ğŸ”§ Setting up SiteOptz AI Tools Scraping System\n');
console.log('='.repeat(60));

async function setup() {
  try {
    // Create necessary directories
    console.log('\nğŸ“ Creating directory structure...');
    const directories = [
      'data',
      'data/scraped',
      'data/merged',
      'data/merged/categories',
      'data/analytics',
      'data/reports'
    ];
    
    for (const dir of directories) {
      const dirPath = path.join(__dirname, dir);
      await fs.mkdir(dirPath, { recursive: true });
      console.log(`   âœ… ${dir}/`);
    }
    
    // Check for .env file
    console.log('\nğŸ”‘ Checking configuration...');
    const envPath = path.join(__dirname, '.env');
    try {
      await fs.access(envPath);
      console.log('   âœ… .env file found');
      
      // Read and validate .env
      const envContent = await fs.readFile(envPath, 'utf8');
      if (envContent.includes('FIRECRAWL_API_KEY')) {
        console.log('   âœ… API key configured');
      } else {
        console.log('   âš ï¸ API key not found in .env');
      }
    } catch {
      console.log('   âš ï¸ .env file not found');
      console.log('   Creating .env.example for reference...');
      
      const exampleContent = `# Firecrawl API Configuration
FIRECRAWL_API_KEY=your-api-key-here

# Scraping Configuration
MAX_REQUESTS=100
DELAY_MS=2000
CONCURRENT_REQUESTS=3

# Data Output
OUTPUT_DIR=./data
WEBSITE_DATA_PATH=../public/data/aiToolsData.json`;
      
      await fs.writeFile(path.join(__dirname, '.env.example'), exampleContent);
      console.log('   âœ… Created .env.example');
    }
    
    // Check dependencies
    console.log('\nğŸ“¦ Checking dependencies...');
    try {
      require('@mendable/firecrawl-js');
      console.log('   âœ… Firecrawl package installed');
    } catch {
      console.log('   âš ï¸ Firecrawl not installed. Run: npm install');
    }
    
    try {
      require('dotenv');
      console.log('   âœ… Dotenv package installed');
    } catch {
      console.log('   âš ï¸ Dotenv not installed. Run: npm install');
    }
    
    // Test category normalization
    console.log('\nğŸ·ï¸ Testing category normalization...');
    const { normalizeCategory } = require('./scrape-new-ai-tools');
    const testCases = [
      { input: 'text', expected: 'text-generation' },
      { input: 'image', expected: 'image-generation' },
      { input: 'code', expected: 'code-generation' },
      { input: 'chatbot', expected: 'chatbots' },
      { input: 'voice', expected: 'voice-ai' }
    ];
    
    let passed = 0;
    testCases.forEach(test => {
      const result = normalizeCategory(test.input);
      if (result === test.expected) {
        console.log(`   âœ… "${test.input}" â†’ "${result}"`);
        passed++;
      } else {
        console.log(`   âŒ "${test.input}" â†’ "${result}" (expected: "${test.expected}")`);
      }
    });
    
    console.log(`   ${passed}/${testCases.length} tests passed`);
    
    // Check for existing data
    console.log('\nğŸ“Š Checking existing data...');
    const dataPath = path.join(__dirname, '../public/data/aiToolsData.json');
    try {
      const data = await fs.readFile(dataPath, 'utf8');
      const tools = JSON.parse(data);
      const toolCount = Array.isArray(tools) ? tools.length : 0;
      console.log(`   âœ… Found ${toolCount} existing tools`);
      
      if (toolCount > 0) {
        // Analyze existing categories
        const categories = new Set(tools.map(t => t.category).filter(Boolean));
        console.log(`   ğŸ“‚ ${categories.size} categories found`);
      }
    } catch {
      console.log('   â„¹ï¸ No existing tools data found (will create new)');
    }
    
    // Summary
    console.log('\n' + '='.repeat(60));
    console.log('âœ… Setup complete!\n');
    
    console.log('ğŸ“ Next Steps:');
    console.log('1. Get your Firecrawl API key from: https://firecrawl.dev');
    console.log('2. Add it to your .env file: FIRECRAWL_API_KEY=your-key');
    console.log('3. Run the scraper: npm run scrape-all');
    console.log('\nğŸ’¡ Available Commands:');
    console.log('   npm run scrape-all    - Run complete scraping pipeline');
    console.log('   npm run scrape-new    - Scrape new tools only');
    console.log('   npm run merge         - Merge scraped data with existing');
    console.log('   npm run analytics     - Generate analytics report');
    console.log('   npm run clean         - Clean up data directories');
    console.log('\n');
    
  } catch (error) {
    console.error('âŒ Setup failed:', error);
    process.exit(1);
  }
}

setup();