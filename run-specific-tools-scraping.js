#!/usr/bin/env node

/**
 * Main Runner for Specific AI Tools Scraping Project
 * Orchestrates the complete process of scraping and integrating new AI tools
 */

import { scrapeAllTools } from './scrape-specific-ai-tools.js';
import { mergeSpecificTools } from './merge-specific-tools.js';
import { TOTAL_TOOLS_COUNT } from './scripts/specific-tools-config.js';
import fs from 'fs';
import path from 'path';

/**
 * Configuration and settings
 */
const CONFIG = {
  dryRun: process.argv.includes('--dry-run'),
  skipScraping: process.argv.includes('--skip-scraping'),
  skipMerging: process.argv.includes('--skip-merging'),
  testMode: process.argv.includes('--test'),
  verbose: process.argv.includes('--verbose') || process.argv.includes('-v')
};

/**
 * Display startup banner
 */
function displayBanner() {
  console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
  console.log('‚ïë            SiteOptz.ai Specific AI Tools Scraper            ‚ïë');
  console.log('‚ïë                                                              ‚ïë');
  console.log(`‚ïë  Target: ${TOTAL_TOOLS_COUNT.toString().padEnd(2)} specific AI tools across 17 categories      ‚ïë`);
  console.log('‚ïë  Method: Firecrawl API with LLM extraction                  ‚ïë');
  console.log('‚ïë  Output: Comprehensive tool database with SEO metadata      ‚ïë');
  console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
  console.log('');
  
  if (CONFIG.dryRun) {
    console.log('üß™ DRY RUN MODE - No actual scraping will be performed');
  }
  
  if (CONFIG.testMode) {
    console.log('üîß TEST MODE - Will scrape only 3 tools for testing');
  }
  
  console.log('');
}

/**
 * Check prerequisites
 */
function checkPrerequisites() {
  const checks = [];
  
  // Check for Firecrawl API key
  const apiKey = process.env.FIRECRAWL_API_KEY || 'fc-6e7e6312953b47069452e67509d9f857';
  if (!apiKey || apiKey === 'your-api-key-here') {
    checks.push('‚ùå FIRECRAWL_API_KEY not configured');
  } else {
    checks.push('‚úÖ Firecrawl API key configured');
  }
  
  // Check data directories
  const dataDir = path.join(process.cwd(), 'data', 'siteoptz');
  const publicDataDir = path.join(process.cwd(), 'public', 'data');
  
  if (!fs.existsSync(dataDir)) {
    fs.mkdirSync(dataDir, { recursive: true });
    checks.push('‚úÖ Created data directory');
  } else {
    checks.push('‚úÖ Data directory exists');
  }
  
  if (!fs.existsSync(publicDataDir)) {
    checks.push('‚ö†Ô∏è Public data directory missing (will be created)');
  } else {
    checks.push('‚úÖ Public data directory exists');
  }
  
  // Check configuration file
  const configFile = path.join(process.cwd(), 'scripts', 'specific-tools-config.js');
  if (!fs.existsSync(configFile)) {
    checks.push('‚ùå Configuration file missing');
    return { passed: false, checks };
  } else {
    checks.push('‚úÖ Configuration file found');
  }
  
  const hasErrors = checks.some(check => check.startsWith('‚ùå'));
  
  return {
    passed: !hasErrors,
    checks: checks
  };
}

/**
 * Display progress and statistics
 */
function displayProgress() {
  const dataDir = path.join(process.cwd(), 'data', 'siteoptz');
  const summaryFile = path.join(dataDir, 'scraping-summary.json');
  
  if (fs.existsSync(summaryFile)) {
    try {
      const summary = JSON.parse(fs.readFileSync(summaryFile, 'utf8'));
      
      console.log('üìä Scraping Progress:');
      console.log(`   - Total tools: ${summary.totalTools}`);
      console.log(`   - Successful: ${summary.successfulScrapes}`);
      console.log(`   - Failed: ${summary.failedScrapes}`);
      console.log(`   - Duration: ${summary.durationMinutes} minutes`);
      console.log(`   - Success rate: ${((summary.successfulScrapes / summary.totalTools) * 100).toFixed(1)}%`);
      
      if (summary.failedTools && summary.failedTools.length > 0) {
        console.log('\n‚ö†Ô∏è Failed tools:');
        summary.failedTools.slice(0, 5).forEach(failure => {
          console.log(`   - ${failure.tool}: ${failure.error.substring(0, 50)}...`);
        });
        if (summary.failedTools.length > 5) {
          console.log(`   ... and ${summary.failedTools.length - 5} more`);
        }
      }
    } catch (error) {
      console.log('‚ö†Ô∏è Could not read scraping summary');
    }
  }
}

/**
 * Run test mode with limited tools
 */
async function runTestMode() {
  console.log('üîß Running in test mode with 3 tools...\n');
  
  // Import and modify config for testing
  const { specificToolsConfig } = await import('./scripts/specific-tools-config.js');
  
  // Take first 3 tools from first category
  const firstCategory = Object.keys(specificToolsConfig)[0];
  const testTools = specificToolsConfig[firstCategory].slice(0, 3);
  
  console.log('üìã Test tools:');
  testTools.forEach((tool, index) => {
    console.log(`   ${index + 1}. ${tool.name} (${tool.url})`);
  });
  
  console.log('\nüöÄ Starting test scraping...');
  
  // Note: In a full implementation, we'd need to pass testTools to the scraper
  // For now, we'll proceed with the full scraper but note this limitation
  console.log('‚ö†Ô∏è Test mode note: Full scraper will run. Consider implementing test tool filtering.');
}

/**
 * Main execution flow
 */
async function main() {
  displayBanner();
  
  // Check prerequisites
  console.log('üîç Checking prerequisites...');
  const prereqCheck = checkPrerequisites();
  
  prereqCheck.checks.forEach(check => console.log(`   ${check}`));
  
  if (!prereqCheck.passed) {
    console.error('\n‚ùå Prerequisites not met. Please fix the issues above.');
    process.exit(1);
  }
  
  console.log('\n‚úÖ All prerequisites met!\n');
  
  // Test mode
  if (CONFIG.testMode) {
    await runTestMode();
  }
  
  let scrapingResults = null;
  
  // Phase 1: Scraping
  if (!CONFIG.skipScraping && !CONFIG.dryRun) {
    console.log('üöÄ Phase 1: Scraping AI Tools');
    console.log('‚ïê'.repeat(50));
    
    try {
      scrapingResults = await scrapeAllTools();
      console.log('\n‚úÖ Scraping phase completed successfully!');
    } catch (error) {
      console.error('\n‚ùå Scraping phase failed:', error.message);
      
      // Check if partial results exist
      const dataDir = path.join(process.cwd(), 'data', 'siteoptz');
      const specificToolsFile = path.join(dataDir, 'specific-tools.json');
      
      if (fs.existsSync(specificToolsFile)) {
        console.log('üìÇ Partial results found, proceeding with merge...');
      } else {
        console.error('‚ùå No scraped data available. Exiting.');
        process.exit(1);
      }
    }
  } else if (CONFIG.skipScraping) {
    console.log('‚è≠Ô∏è Skipping scraping phase (--skip-scraping flag)');
  } else if (CONFIG.dryRun) {
    console.log('üß™ Dry run: Would scrape tools here');
  }
  
  // Display progress
  if (!CONFIG.dryRun) {
    displayProgress();
  }
  
  // Phase 2: Merging
  if (!CONFIG.skipMerging && !CONFIG.dryRun) {
    console.log('\nüîÑ Phase 2: Merging with Existing Database');
    console.log('‚ïê'.repeat(50));
    
    try {
      await mergeSpecificTools();
      console.log('\n‚úÖ Merging phase completed successfully!');
    } catch (error) {
      console.error('\n‚ùå Merging phase failed:', error.message);
      console.error('üí° You can retry merging later with: node merge-specific-tools.js');
    }
  } else if (CONFIG.skipMerging) {
    console.log('\n‚è≠Ô∏è Skipping merging phase (--skip-merging flag)');
  } else if (CONFIG.dryRun) {
    console.log('\nüß™ Dry run: Would merge data here');
  }
  
  // Final summary
  console.log('\nüéâ Process Complete!');
  console.log('‚ïê'.repeat(50));
  
  if (!CONFIG.dryRun) {
    const dataDir = path.join(process.cwd(), 'data', 'siteoptz');
    const publicDataDir = path.join(process.cwd(), 'public', 'data');
    
    console.log('üìÅ Generated files:');
    
    // Check for generated files
    const generatedFiles = [
      { path: path.join(dataDir, 'specific-tools.json'), desc: 'Raw scraped data' },
      { path: path.join(dataDir, 'scraping-summary.json'), desc: 'Scraping summary' },
      { path: path.join(dataDir, 'merge-summary.json'), desc: 'Merge summary' },
      { path: path.join(publicDataDir, 'aiToolsData.json'), desc: 'Updated tools database' },
      { path: path.join(publicDataDir, 'aiToolsData-backup.json'), desc: 'Database backup' }
    ];
    
    generatedFiles.forEach(file => {
      if (fs.existsSync(file.path)) {
        const stats = fs.statSync(file.path);
        const sizeKB = (stats.size / 1024).toFixed(1);
        console.log(`   ‚úÖ ${file.desc}: ${file.path} (${sizeKB}KB)`);
      } else {
        console.log(`   ‚ùå ${file.desc}: Not found`);
      }
    });
    
    // Next steps
    console.log('\nüìã Next Steps:');
    console.log('   1. Review the scraped data for quality');
    console.log('   2. Test the updated website locally');
    console.log('   3. Commit changes to git');
    console.log('   4. Deploy to production');
    
    console.log('\nüí° Useful commands:');
    console.log('   - View scraping summary: cat data/siteoptz/scraping-summary.json');
    console.log('   - View merge summary: cat data/siteoptz/merge-summary.json');
    console.log('   - Test locally: npm run dev');
    console.log('   - Build production: npm run build');
  }
  
  console.log('\n‚ú® Happy scraping! ‚ú®');
}

// Handle command line arguments
if (process.argv.includes('--help') || process.argv.includes('-h')) {
  console.log(`
AI Tools Scraping Runner

Usage: node run-specific-tools-scraping.js [options]

Options:
  --dry-run         Simulate the process without actual scraping
  --skip-scraping   Skip the scraping phase (useful if data already exists)
  --skip-merging    Skip the merging phase (scrape only)
  --test            Run in test mode with limited tools
  --verbose, -v     Enable verbose logging
  --help, -h        Show this help message

Examples:
  node run-specific-tools-scraping.js                    # Full process
  node run-specific-tools-scraping.js --test             # Test with 3 tools
  node run-specific-tools-scraping.js --dry-run          # Simulate process
  node run-specific-tools-scraping.js --skip-scraping    # Merge existing data only
`);
  process.exit(0);
}

// Run main function
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch(error => {
    console.error('\nüí• Fatal error:', error.message);
    if (CONFIG.verbose) {
      console.error(error.stack);
    }
    process.exit(1);
  });
}